#!/usr/bin/python3
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

# standard python imports
import argparse
import os
import sys
import numpy as np
import math
import array
import hashlib as hl
from shutil import which
import subprocess as subproc
import struct

# local module which compiles the provided flatbuffer schema into it's
# python interface if it doesn't exist or needs updating
import EnsureSchemaCompiled

# import flatbuffers and tflite schema interface
import flatbuffers as fb
import tflite.Model as TFLModel
import tflite.BuiltinOptions as BuiltinOptions
import tflite.Conv2DOptions as Conv2DOptions
import tflite.Pool2DOptions as Pool2DOptions
import tflite.DepthwiseConv2DOptions as DepthwiseConv2DOptions
import tflite.BuiltinOperator as BuiltinOperator
import tflite.Metadata as Metadata
import tflite.Buffer as Buffer

# import flatbuffer to cc & h converter
import flatbuffer_2_tfl_micro as code_gen


def load_flatbuffer():
  file_name = FLAGS.file_name
  # base_name = file_name
  # if base_name[-7:] == ".tflite":
  #  base_name = base_name[:-7]

  try:
    tflite_file = open(file_name, 'rb')

    print("=" * (len(file_name) + 35))
    print("====== Reading flatbuffer \"%s\" ======" % file_name)
    print("=" * (len(file_name) + 35))
    buf = bytearray(tflite_file.read())
    print("Read %d bytes okay." % len(buf))

    n = fb.encode.Get(fb.packer.uoffset, buf, 0)
    # print("n = %d" % n)
    model = TFLModel.ModelT.InitFromBuf(buf, n)
    print("Loaded TFL%s flatbuffer" % model.version)

    return model

  except IOError:
    print("Failed to open file \"%s\"." % file_name)
    quit()


def get_builtin_operator_name(builtin_code):
  """
  Horrific function to reverse the crazy way that flatbuffers stores enums
  it works great for checking specific values, but you have to do this to
  get a value string from an index!
  :param builtin_code: index of builtin operator type
  :return: string of the operator name
  """
  keys = list(BuiltinOperator.BuiltinOperator.__dict__.keys())
  values = list(BuiltinOperator.BuiltinOperator.__dict__.values())
  builtin_name = keys[values.index(builtin_code)]
  return builtin_name


def list_operations(model):

  print("Model subgraph(%d) contains %d operations" %
        (FLAGS.index,
         len(model.subgraphs[FLAGS.index].operators)))

  for i, op in enumerate(model.subgraphs[FLAGS.index].operators):
    operator_code = model.operatorCodes[op.opcodeIndex]
    operator_description = get_builtin_operator_name(operator_code.builtinCode)
    operator_description = operator_description.title()
    if operator_code.customCode is not None:
      operator_description = operator_code.customCode.decode('utf-8')
      operator_description += " (custom)"

    operator_description += " v%d" % operator_code.version

    print("[%3d] %s" % (i, operator_description))


def generate_buffer_offsets_metadata(offsets, sub_graph=0, version=0):
  words_list = [version, sub_graph, len(offsets)] + offsets
  return struct.pack('<'+'I'*len(words_list), *words_list)


def pre_allocate_memory(model):

  output_filename = FLAGS.pre_allocate_memory[0]
  print("Allocating memory and saving flatbuffer to [%s]" % output_filename)

  # TODO actually pre-allocate memory

  # create new buffer to hold the metadata content
  metadata_buffer = Buffer.BufferT()
  metadata = generate_buffer_offsets_metadata([4, 8, 12, 16],
                                              sub_graph=FLAGS.index)
  metadata_buffer.data = metadata
  #  bytearray("This is the test metadata. honest!", 'utf8')
  if model.buffers is None:
    model.buffers = []
  new_buffer_idx = len(model.buffers)
  model.buffers.append(metadata_buffer)

  # Add metadata item to model, if there is already an
  # offline memory allocation entry then update it, otherwise add
  # a new metadata entry
  if model.metadata is None:
    model.metadata = []

  new_metadata = Metadata.MetadataT()
  new_metadata.name = "OfflineMemoryAllocation"
  new_metadata.buffer = new_buffer_idx
  model.metadata.append(new_metadata)

  # print("Rebuild and save modified model")
  builder = fb.Builder(1024)
  packed_model = model.Pack(builder)
  builder.Finish(packed_model, file_identifier=bytearray("TFL3", 'utf-8'))
  new_model_buffer = builder.Output()

  new_tflite_file = open(output_filename, 'wb')
  new_tflite_file.write(new_model_buffer)
  print("Completed writing modifiled flatbuffer to \"%s\"" % output_filename)


def list_meta_data(model):

  metadata = model.metadata
  if metadata is None:
    metadata = []
  print("Model contains %d meta data entries" % len(metadata))
  for i, m in enumerate(metadata):
    print("[%d] \"%s\" (%d bytes of data stored in buffer %d)" %
          (i,
           m.name.decode("utf-8"),
           len(model.buffers[m.buffer].data),
           m.buffer))


def show_offline_mem_alloc(model):
  """
  Function to validate and show any offline memory allocation
  metadata contained in the given model object
  :param model: model object to inspect
  :return: None
  """
  oma_meta_idxs = []
  oma_buffers = []
  metadata = model.metadata
  if metadata is None:
    metadata = []
  for i, m in enumerate(metadata):
    if m.name.decode('utf-8') == "OfflineMemoryAllocation":
      oma_meta_idxs.append(i)
      oma_buffers.append(m.buffer)

  if len(oma_buffers) == 0:
    print("No offline memory allocation metadata present.")
  else:
    for idx, buffer_idx in enumerate(oma_buffers):
      print("\nMetadata entry [%2d] - OfflineMemoryAllocation" %
            oma_meta_idxs[idx])

      buffer = model.buffers[buffer_idx].data
      word_list = struct.unpack('<' + 'I' * int(len(buffer)/4), buffer)

      if (len(word_list) == 0):
        print("Error: Zero length metadata found!")
        continue

      version = word_list[0]
      print("Format version %d" % version)
      version_supported = False

      # Currently the only defined version of this standard
      if version == 0:
        version_supported = True
        # verify size of metadata buffer
        if len(word_list) < 3:
          print("Error: Metadata buffer too short for header!")
          continue
        if len(word_list) < (3+word_list[2]):
          print("Error: Metadata buffer too short for given offset count!")
          continue
        if len(word_list) < (3+word_list[2]):
          print("Error: Metadata buffer too long for given offset count!")
          continue

        print("Subgraph %d" % word_list[1])
        for i, offset in enumerate(word_list[2:]):
          print("Offset [%3d] %d bytes" % (i, offset))

      if not version_supported:
        print("Error: unsupported format version!")

def write_cc_file():
  try:
    tflite_file = open(FLAGS.file_name, 'rb')

    print("=" * (len(FLAGS.file_name) + 35))
    print("====== Reading flatbuffer \"%s\" ======" % FLAGS.file_name)
    print("=" * (len(FLAGS.file_name) + 35))
    buf = bytearray(tflite_file.read())
    print("Read %d bytes okay." % len(buf))

    header_comment = ("Automatically generated by tflite_micro_utils "
                      "using the command:\n"
                      "tflite_micro_utils -wc %s %s %s" %
                      (FLAGS.generate_c[0],
                       FLAGS.generate_c[1],
                       FLAGS.file_name))

    base_filename = os.path.splitext(FLAGS.generate_c[0])[0]
    identifier = FLAGS.generate_c[1]

    print("Generating c source files containing flatbuffer:")
    print("  - %s.cc\n  - %s.h" %
          (base_filename, base_filename))

    code_gen.write_tf_lite_micro_model(buf,
                                       base_file_name=base_filename,
                                       data_variable_name=identifier,
                                       header_comment=header_comment)

    print("Complete")

  except IOError:
    print("Failed to open file \"%s\"." % FLAGS.file_name)
    quit()


def main():

  if FLAGS.operations:
    list_operations(load_flatbuffer())

  if FLAGS.pre_allocate_memory:
    pre_allocate_memory(load_flatbuffer())

  if FLAGS.meta_data:
    list_meta_data(load_flatbuffer())

  if FLAGS.offline_mem_alloc:
    show_offline_mem_alloc(load_flatbuffer())

  if FLAGS.generate_c:
    write_cc_file()


if __name__ == '__main__':
  parser = argparse.ArgumentParser()
  parser.add_argument('file_name', type=str,
                      help='Name of the tflite flatbuffer file to load.')
  parser.add_argument('-pm', '--pre_allocate_memory',
                      metavar='Output_File',
                      nargs=1, default='',
                      help='Pre allocate intermediate tensor buffers, save'
                           'in the metadata table and write to new flatbuffer')
  parser.add_argument('-g', '--generate_c',
                      metavar='Output_File Identifier',
                      nargs=2, default='',
                      help='Write flatbuffer to cc & h files.')
  parser.add_argument('-i', '--index',
                      metavar='Index',
                      type=int, default=0,
                      help='Index of the subgraph to analyse. Defaults to 0')
  parser.add_argument('-o', '--operations',
                      action="store_true",
                      help='Print a summary of the operations used in '
                           'this model.')
  parser.add_argument('-ot', '--op_types',
                      action="store_true",
                      help='Print a summary of the operation types used in '
                           'this model.')
  parser.add_argument('-md', '--meta_data',
                      action="store_true",
                      help="Prints any meta-data members stored in this "
                           "tflite flatbuffer.")
  parser.add_argument('-oma', '--offline_mem_alloc',
                      action="store_true",
                      help='Print details of any offline memory allocation '
                           'metadata present.'
                           'this model.')
  parser.add_argument('-b', '--buffers',
                      action="store_true",
                      help="Prints a summary of all memory buffers defined "
                           "in this model.")

  """parser.add_argument('-w', '--weights', action="store_true",
                      help='Print detail of the weights of this model.')
  parser.add_argument('-m', '--memory',
                      action="store_true",
                      help='Print details of memory allocation required by'
                           ' this model.')
  parser.add_argument('-t', '--tensors',
                      action="store_true",
                      help='Print details of the tensors used in this model.')
  parser.add_argument('-s', '--save_csv',
                      action="store_true",
                      help='Write the selected detail to a set of CSV files.')
  parser.add_argument('-om', '--optimise_memory',
                      action="store_true",
                      help='Uses various algorithms to precalculate an optimal '
                           'memory useage pattern.')"""

  FLAGS, unparsed = parser.parse_known_args()

  main()
